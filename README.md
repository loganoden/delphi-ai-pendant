# DELPHI: Wearable AI Assistant for the Visually Impaired

**Duration:** March 2025  
**Event:** MakeOHI/O 2025 â€“ 99P Labs *Building the Future with On-Device LLMs* Challenge  
**Team Size:** 4 (Runner-Up Placement)  

---

## ğŸ“˜ Overview
**DELPHI** is a wearable AI pendant prototype designed to assist visually impaired users by detecting faces and audibly identifying recognized individuals in real time, completely **on-device**.  
Developed in just **24 hours** during *MakeOHI/O 2025*, the project integrates multiple edge computing systems and lightweight AI models to deliver private, low-latency recognition and communication without cloud dependence.

---

## âš™ï¸ Technical Implementation
- **Distributed Edge System:** Utilized a **Raspberry Pi 5** for face detection and a **Raspberry Pi 4** for recognition, local LLM responses, and text-to-speech.  
- **Computer Vision:** Enhanced face detection accuracy through optimized face-cropping using **OpenCV** and **Ultralytics YOLO**.  
- **Local AI Models:** Integrated **TinyLlama** for on-device language understanding, **Piper TTS** for speech output, and **SpeechRecognition** for hands-free interaction.  
- **Performance:** Delivered full on-device inference with multi-identity support, reducing latency and ensuring privacy by eliminating cloud processing.

---

## ğŸ§  Skills and Technologies
**Languages & Libraries:** Python Â· OpenCV Â· Ultralytics YOLO Â· SpeechRecognition  
**Hardware:** Raspberry Pi 5 Â· Raspberry Pi 4  
**AI Tools:** TinyLlama Â· Piper TTS  
**Domains:** Edge Computing Â· Computer Vision Â· Machine Learning Â· Assistive Technology  
**Soft Skills:** Strategic Collaboration Â· Rapid Prototyping  

---

## ğŸ† Results
Runner-up at **99P Labsâ€™ Building the Future with On-Device LLMs Challenge** (*MakeOHI/O 2025*), recognized for innovation in edge-based AI and accessibility technology.

---

## ğŸ“„ License / Documentation
Future documentation and demo materials will be provided as development continues.
